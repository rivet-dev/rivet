export const title = "A Radically Simpler Architecture";
export const act = "Act I";
export const subtitle = "Why actors eliminate complexity instead of managing it";

import {
	Narrative,
	Concept,
	Direction,
	Separator,
	ActEnd,
	Image,
} from "@/app/(v2)/learn/components/mdx";

import oldArch from "./scene-1/old-arch.png";
import actorArch from "./scene-1/actor-arch.png";
import isolatedState from "./scene-1/isolated-state.png";
import messagePassing from "./scene-1/message-passing.png";
import locationTransparency from "./scene-1/location-transparency.png";
import horizontalScaling from "./scene-1/horizontal-scaling.png";

## How Backends Become Complex

<Narrative>
The typical backend architecture follows a familiar pattern. A web server connects to a database. Traffic grows, so you add Redis for caching. You need async processing, so you add Kafka. You need coordination, so you add distributed locks.
</Narrative>

Each layer solves a specific problem but introduces new ones. Cache invalidation bugs appear in production. Messages get lost in queues. Deadlocks take down the entire system. This results in coordinating transactions across services, debugging race conditions, and managing data consistency across multiple systems.

<Image src={oldArch} alt="Traditional backend architecture with separate layers for web server, cache, database, and message queue" />

## Every Solution Creates A Problem

As you add compnents to your architecutre to solve these problems, in turn you create new problems for yourself:

- **Caching**: brings cache invalidation bugs, stale data, and thundering herd problems.
- **Message queues**: bring message ordering issues, exactly-once delivery problems, and dead letter queue monitoring.
- **Distributed locks**: bring deadlocks, lock timeouts, and split-brain scenarios.
- **Multiple services**: bring distributed transactions, eventual consistency, and network partition handling.

These problems compound. A cache invalidation bug combined with a race condition can cause data corruption that's nearly impossible to reproduce or debug.

New features touch caching logic, queue handlers, database schemas, and service boundaries. Complexity grows exponentially with each addition.

Worse, these aren't bugs you can unit test for. They're emergent behaviors that only appear under load when it matters most.

<Separator />

## How We Got Here

The way you've designed your app is through an **age-old practice of "separating state and compute."** This solidified in the 1980s when client-server architecture emerged and everyone started running databases on dedicated machines.

This came from the fact that computers were slow and had limited resources. Running application code and database operations on the same machine meant they'd fight over CPU and memory, making both perform poorly. Separating them protected databases from compute overhead. This tradeoff made sense when CPU and memory were severly limited.

## 40 Years Later

Those constraints from fourty years ago no longer apply to today's servers. Modern CPUs are orders of magnitude faster, and memory is abundant and cheap. **Application bottlenecks has shifted from local compute to network latency and locks.**

A Postgres query over the network takes 1-10ms minimum. The same query on a local SQLite database (running in the same process as your application) takes 0.01-0.1ms. The network round trip and related locks is now the expensive part, not running the application and database on the same machine.

**Combining compute and storage eliminates the biggest source of latency for modern applications**: network trips to the database and locsk.

Additionally, **it also eliminates entire categories of bugs**. No network means no network partitions. No shared state means no race conditions. No locks means no deadlocks.

<Separator />

## The Actor Model: Combining Compute & Storage

Actors are the opposite of "separating compute and storage." **They put compute and storage in the same place** and load state into memory when awoken.

Each actor's **state is isolated to itself** and cannot be read by any other programs. Instead, you communicate with actors over the network via actions.

They're like mini-servers: they can accept and respond to network requests and even send requests themselves without being prompted. They remain running as a long-lived process with in-memory state until they decide to go to sleep.

<Image src={actorArch} alt="Actor architecture showing compute and storage combined in isolated actors" className="max-h-[500px]" />

## The 4 Properties That Eliminate Complexity

By combining compute and storage, actors present a few key properties that eliminate entire categories of problems.

### Isolated State

Each actor **manages its own private state**. No other process can access an actor's state.

This eliminates race conditions (can't happen when only one process touches the data), deadlocks (no locks means no deadlocks), cache invalidation (no shared cache to invalidate), and read-after-write inconsistencies (your writes are immediately visible to you).

Debugging becomes straightforward: the actor's state is the single source of truth. There's no need to reconstruct state from multiple systems or reason about eventual consistency across caches, databases, and message queues.

As your app grows, new features affect a limited number of actors which have a limited scope. Changes don't ripple through shared state or risk breaking unrelated parts of your system.

<Image src={isolatedState} alt="Diagram showing actors with isolated state that cannot be accessed by other processes" className="max-h-[500px]" />

### Message-Based Communication

Actors **talk through actions and events**, not direct state access. This makes it easier to scale actors since they can scale horizontally across multiple machines and still communicate efficiently.

**Actors frequently talk to each other** to build larger systems that scale well. We'll be talking a lot about patterns like this in this course.

<Image src={messagePassing} alt="Diagram showing actors communicating through messages and events" className="max-h-[500px]" />

### Location Transparency

Actors can run on any machine in a cluster and still **send messages between actors regardless of the host machine**. Rivet automatically handles intelligent load balancing of actors and routing between actors.

The same code will run whether you have 1 or 1,000 machines without complex network configuration, DNS, or pub/sub systems.

<Image src={locationTransparency} alt="Diagram showing actors communicating across different machines in a cluster" />

### Horizontal Scaling

Actors are designed to transparently interact with other actors regardless of what machine they run on. This makes actors easy to scale by **just adding more machines** for actors to run on when you need it.

Load spreads naturally since actors are small, lightweight units. No complex sharding logic or coordination needed.

<Image src={horizontalScaling} alt="Diagram showing actors distributed across multiple machines for horizontal scaling" className="max-h-[500px]" />

<Separator />

## Putting It All Together: A Radically Simpler Architecture

When you switch to actors, your architecture no longer needs:

- **Redis/Memcached**: Caching is built-in (state lives with compute).
- **Kafka/RabbitMQ/SQS**: Events and async messaging are built-in.
- **Consul/etcd/ZooKeeper**: No distributed coordination needed.
- **Istio/Linkerd**: Actors handle routing and discovery automatically.
- **Database sharding**: Actors distribute themselves automatically. No shard keys, no rebalancing logic, no cross-shard queries.

New features are new actors or modifications to individual actors, not changes that cascade through your entire system.

